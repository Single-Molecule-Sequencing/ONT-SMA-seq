# SMA-Merge Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Build a CLI tool that discovers MinKNOW run directories, validates basecalling consistency, and produces clean merged or subsampled BAMs with end_reason tagging from POD5 metadata.

**Architecture:** Python package `sma_merge` with modules for discovery (POD5 metadata extraction), validation (run grouping + consistency checks), subsampling (pod5 filter), basecalling (dorado wrapper), and BAM tagging (end_reason from POD5). CLI dispatches to discover/merge/subsample pipelines.

**Tech Stack:** Python 3.10+, pod5 (POD5 I/O), pysam (BAM I/O), numpy (subsampling), subprocess (dorado + pod5 CLI), pytest (testing)

**Test runner:** `cd /tmp/ont-sma-seq && python -m pytest tests/ -v`
**PYTHONPATH:** Configured in `pytest.ini` as `pythonpath = bin`, so imports use `from sma_merge.module import ...`

---

### Task 1: Package Scaffolding + Data Models

**Files:**
- Create: `bin/sma_merge/__init__.py`
- Create: `bin/sma_merge/models.py`
- Test: `tests/test_sma_merge_models.py`

**Step 1: Write the failing test**

```python
# tests/test_sma_merge_models.py
"""Tests for sma_merge data models."""
from __future__ import annotations


def test_run_info_creation():
    from sma_merge.models import RunInfo
    from pathlib import Path

    info = RunInfo(
        run_dir=Path("/tmp/run"),
        flow_cell_id="FBD66244",
        device_id="MD-101527",
        protocol_group_id="test_protocol",
        basecall_model="dna_r10.4.1_e8.2_400bps_hac@v5.2.0",
        sample_id="sample1",
        run_id="abc123",
        sample_rate=5000,
        pod5_dir=Path("/tmp/run/pod5_pass"),
        pod5_count=10,
        mod_base_models="",
    )
    assert info.flow_cell_id == "FBD66244"
    assert info.basecall_model == "dna_r10.4.1_e8.2_400bps_hac@v5.2.0"


def test_run_group_creation():
    from sma_merge.models import RunInfo, RunGroup
    from pathlib import Path

    run = RunInfo(
        run_dir=Path("/tmp/run"),
        flow_cell_id="FBD66244",
        device_id="MD-101527",
        protocol_group_id="test_protocol",
        basecall_model="dna_r10.4.1_e8.2_400bps_hac@v5.2.0",
        sample_id="",
        run_id="abc123",
        sample_rate=5000,
        pod5_dir=Path("/tmp/run/pod5_pass"),
        pod5_count=10,
        mod_base_models="",
    )
    group = RunGroup(
        flow_cell_id="FBD66244",
        runs=[run],
        basecall_model="dna_r10.4.1_e8.2_400bps_hac@v5.2.0",
        is_consistent=True,
        issues=[],
    )
    assert group.is_consistent
    assert len(group.runs) == 1


def test_merge_result_creation():
    from sma_merge.models import MergeResult
    from pathlib import Path

    result = MergeResult(
        merged_pod5=Path("/tmp/out/merged.pod5"),
        output_bam=Path("/tmp/out/merged.bam"),
        total_reads=5000,
        reads_tagged=4950,
    )
    assert result.total_reads == 5000
```

**Step 2: Run test to verify it fails**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_models.py -v`
Expected: FAIL with "ModuleNotFoundError: No module named 'sma_merge'"

**Step 3: Write minimal implementation**

```python
# bin/sma_merge/__init__.py
"""SMA-seq experiment merge tool."""
__version__ = "0.1.0"
```

```python
# bin/sma_merge/models.py
"""Data models for sma-merge."""
from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path


@dataclass
class RunInfo:
    """Metadata for a single MinKNOW run directory."""

    run_dir: Path
    flow_cell_id: str
    device_id: str
    protocol_group_id: str
    basecall_model: str
    sample_id: str
    run_id: str
    sample_rate: int
    pod5_dir: Path
    pod5_count: int
    mod_base_models: str


@dataclass
class RunGroup:
    """A group of runs that should be merged (same flowcell/sample)."""

    flow_cell_id: str
    runs: list[RunInfo]
    basecall_model: str
    is_consistent: bool
    issues: list[str] = field(default_factory=list)


@dataclass
class MergeResult:
    """Result of a merge or subsample operation."""

    merged_pod5: Path
    output_bam: Path
    total_reads: int
    reads_tagged: int
```

**Step 4: Run test to verify it passes**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_models.py -v`
Expected: 3 PASSED

**Step 5: Commit**

```bash
cd /tmp/ont-sma-seq && git add bin/sma_merge/__init__.py bin/sma_merge/models.py tests/test_sma_merge_models.py && git commit -m "feat(sma-merge): add package scaffolding and data models"
```

---

### Task 2: Discovery Module

**Files:**
- Create: `bin/sma_merge/discover.py`
- Test: `tests/test_sma_merge_discover.py`

**Context:** Discovery scans an experiment path for MinKNOW run directories by looking for `pod5_pass/` subdirectories. It reads metadata from the first POD5 file in each run (all POD5s in a run share the same `run_info`). The POD5 Python API: `pod5.Reader(path)` returns a context manager; `reader.reads()` yields read objects with `.run_info.context_tags` (dict), `.run_info.tracking_id` (dict), `.run_info.sample_rate` (int).

**Step 1: Write the failing test**

```python
# tests/test_sma_merge_discover.py
"""Tests for MinKNOW run discovery."""
from __future__ import annotations

from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest


def _make_mock_reader(flow_cell_id="FBD66244", device_id="MD-101527",
                      protocol_group="test", model="dna_r10.4.1_e8.2_400bps_hac@v5.2.0",
                      sample_id="", run_id="abc123", sample_rate=5000):
    """Create a mock pod5 Reader that yields one read with given metadata."""
    mock_read = MagicMock()
    mock_read.run_info.context_tags = {
        "basecall_model_simplex": model,
        "basecall_models_modified": "",
    }
    mock_read.run_info.tracking_id = {
        "flow_cell_id": flow_cell_id,
        "device_id": device_id,
        "protocol_group_id": protocol_group,
        "sample_id": sample_id,
        "run_id": run_id,
    }
    mock_read.run_info.sample_rate = sample_rate

    reader = MagicMock()
    reader.__enter__ = MagicMock(return_value=reader)
    reader.__exit__ = MagicMock(return_value=False)
    reader.reads.return_value = iter([mock_read])
    return reader


def _make_run_dir(root: Path, name: str = "20251230_1709_MD-101527_FBD66244_abc123"):
    """Create a MinKNOW-style directory with a dummy pod5 file."""
    run_dir = root / "no_sample_id" / name
    pod5_dir = run_dir / "pod5_pass" / "mixed"
    pod5_dir.mkdir(parents=True)
    (pod5_dir / "chunk_0.pod5").touch()
    return run_dir


class TestDiscoverRuns:

    def test_finds_single_run(self, tmp_path):
        _make_run_dir(tmp_path)
        mock_reader = _make_mock_reader()

        with patch("sma_merge.discover.p5.Reader", return_value=mock_reader):
            from sma_merge.discover import discover_runs
            runs = discover_runs(tmp_path)

        assert len(runs) == 1
        assert runs[0].flow_cell_id == "FBD66244"
        assert runs[0].device_id == "MD-101527"
        assert runs[0].basecall_model == "dna_r10.4.1_e8.2_400bps_hac@v5.2.0"
        assert runs[0].pod5_count == 1

    def test_finds_multiple_runs(self, tmp_path):
        _make_run_dir(tmp_path, "20251230_run1_MD_FBD66244_aaa")
        _make_run_dir(tmp_path, "20251231_run2_MD_FBD66244_bbb")
        mock_reader = _make_mock_reader()

        with patch("sma_merge.discover.p5.Reader", return_value=mock_reader):
            from sma_merge.discover import discover_runs
            runs = discover_runs(tmp_path)

        assert len(runs) == 2

    def test_skips_dirs_without_pod5(self, tmp_path):
        # Create a run dir without any pod5 files
        run_dir = tmp_path / "no_sample_id" / "run1"
        (run_dir / "pod5_pass" / "mixed").mkdir(parents=True)
        # No .pod5 file created

        from sma_merge.discover import discover_runs
        runs = discover_runs(tmp_path)
        assert len(runs) == 0

    def test_counts_pod5_files(self, tmp_path):
        run_dir = tmp_path / "no_sample_id" / "run1"
        pod5_dir = run_dir / "pod5_pass" / "mixed"
        pod5_dir.mkdir(parents=True)
        for i in range(5):
            (pod5_dir / f"chunk_{i}.pod5").touch()

        mock_reader = _make_mock_reader()
        with patch("sma_merge.discover.p5.Reader", return_value=mock_reader):
            from sma_merge.discover import discover_runs
            runs = discover_runs(tmp_path)

        assert runs[0].pod5_count == 5


class TestFormatDiscovery:

    def test_format_table(self):
        from sma_merge.discover import format_discovery_table
        from sma_merge.models import RunInfo

        runs = [
            RunInfo(
                run_dir=Path("/tmp/run1"),
                flow_cell_id="FBD66244",
                device_id="MD-101527",
                protocol_group_id="exp_one_nick",
                basecall_model="hac@v5.2.0",
                sample_id="",
                run_id="abc",
                sample_rate=5000,
                pod5_dir=Path("/tmp/run1/pod5_pass"),
                pod5_count=437,
                mod_base_models="",
            ),
        ]
        table = format_discovery_table(runs)
        assert "FBD66244" in table
        assert "MD-101527" in table
        assert "437" in table
```

**Step 2: Run test to verify it fails**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_discover.py -v`
Expected: FAIL with "ModuleNotFoundError: No module named 'sma_merge.discover'"

**Step 3: Write minimal implementation**

```python
# bin/sma_merge/discover.py
"""Discover MinKNOW run directories and extract metadata from POD5 files."""
from __future__ import annotations

from pathlib import Path

import pod5 as p5

from sma_merge.models import RunInfo


def discover_runs(experiment_path: Path) -> list[RunInfo]:
    """Scan experiment_path for MinKNOW run directories.

    Looks for directories containing pod5_pass/ with at least one .pod5 file.
    Reads run metadata from the first POD5 file found in each run.
    """
    runs: list[RunInfo] = []

    for pod5_pass in sorted(experiment_path.rglob("pod5_pass")):
        if not pod5_pass.is_dir():
            continue

        run_dir = pod5_pass.parent
        pod5_files = sorted(pod5_pass.rglob("*.pod5"))
        if not pod5_files:
            continue

        # Read metadata from first POD5 file
        with p5.Reader(pod5_files[0]) as reader:
            for read in reader.reads():
                ri = read.run_info
                ctx = ri.context_tags
                trk = ri.tracking_id
                runs.append(RunInfo(
                    run_dir=run_dir,
                    flow_cell_id=trk.get("flow_cell_id", ""),
                    device_id=trk.get("device_id", ""),
                    protocol_group_id=trk.get("protocol_group_id", ""),
                    basecall_model=ctx.get("basecall_model_simplex", ""),
                    sample_id=trk.get("sample_id", ""),
                    run_id=trk.get("run_id", ""),
                    sample_rate=ri.sample_rate,
                    pod5_dir=pod5_pass,
                    pod5_count=len(pod5_files),
                    mod_base_models=ctx.get("basecall_models_modified", ""),
                ))
                break  # Only need first read for run-level metadata

    return runs


def format_discovery_table(runs: list[RunInfo]) -> str:
    """Format discovered runs as a human-readable table."""
    if not runs:
        return "No runs found."

    lines = [
        f"{'FlowCell':<12} {'Device':<12} {'Protocol Group':<35} {'Model':<20} {'POD5s':>6}",
        "-" * 90,
    ]
    for r in runs:
        model_short = r.basecall_model.split("@")[-1] if "@" in r.basecall_model else r.basecall_model
        lines.append(
            f"{r.flow_cell_id:<12} {r.device_id:<12} {r.protocol_group_id:<35} {model_short:<20} {r.pod5_count:>6}"
        )
    return "\n".join(lines)
```

**Step 4: Run test to verify it passes**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_discover.py -v`
Expected: 5 PASSED

**Step 5: Commit**

```bash
cd /tmp/ont-sma-seq && git add bin/sma_merge/discover.py tests/test_sma_merge_discover.py && git commit -m "feat(sma-merge): add MinKNOW run discovery module"
```

---

### Task 3: Validation Module

**Files:**
- Create: `bin/sma_merge/validate.py`
- Test: `tests/test_sma_merge_validate.py`

**Context:** Validation groups runs by flow_cell_id, then checks that all runs in a group share the same basecall model and protocol group. Warns if sample_id is empty. Returns a list of RunGroup objects.

**Step 1: Write the failing test**

```python
# tests/test_sma_merge_validate.py
"""Tests for run validation and grouping."""
from __future__ import annotations

from pathlib import Path

import pytest

from sma_merge.models import RunInfo


def _run(flow_cell="FBD66244", device="MD-101527", protocol="exp1",
         model="hac@v5.2.0", sample_id="", run_id="abc"):
    return RunInfo(
        run_dir=Path("/tmp/run"),
        flow_cell_id=flow_cell,
        device_id=device,
        protocol_group_id=protocol,
        basecall_model=model,
        sample_id=sample_id,
        run_id=run_id,
        sample_rate=5000,
        pod5_dir=Path("/tmp/run/pod5_pass"),
        pod5_count=10,
        mod_base_models="",
    )


class TestValidateRuns:

    def test_single_run_is_consistent(self):
        from sma_merge.validate import validate_runs
        groups = validate_runs([_run()])
        assert len(groups) == 1
        assert groups[0].is_consistent
        assert groups[0].flow_cell_id == "FBD66244"

    def test_same_flowcell_grouped(self):
        from sma_merge.validate import validate_runs
        runs = [_run(run_id="aaa"), _run(run_id="bbb")]
        groups = validate_runs(runs)
        assert len(groups) == 1
        assert len(groups[0].runs) == 2

    def test_different_flowcells_separate_groups(self):
        from sma_merge.validate import validate_runs
        runs = [_run(flow_cell="FC1"), _run(flow_cell="FC2")]
        groups = validate_runs(runs)
        assert len(groups) == 2

    def test_inconsistent_model_flagged(self):
        from sma_merge.validate import validate_runs
        runs = [_run(model="hac@v5.2.0"), _run(model="sup@v5.2.0")]
        groups = validate_runs(runs)
        assert len(groups) == 1
        assert not groups[0].is_consistent
        assert any("model" in issue.lower() for issue in groups[0].issues)

    def test_inconsistent_protocol_flagged(self):
        from sma_merge.validate import validate_runs
        runs = [_run(protocol="exp1"), _run(protocol="exp2")]
        groups = validate_runs(runs)
        assert not groups[0].is_consistent
        assert any("protocol" in issue.lower() for issue in groups[0].issues)

    def test_empty_sample_id_warned(self):
        from sma_merge.validate import validate_runs
        groups = validate_runs([_run(sample_id="")])
        assert any("sample_id" in issue.lower() for issue in groups[0].issues)

    def test_nonempty_sample_id_no_warning(self):
        from sma_merge.validate import validate_runs
        groups = validate_runs([_run(sample_id="my_sample")])
        assert not any("sample_id" in issue.lower() for issue in groups[0].issues)


class TestFormatValidation:

    def test_format_includes_status(self):
        from sma_merge.validate import validate_runs, format_validation
        groups = validate_runs([_run()])
        output = format_validation(groups)
        assert "PASS" in output or "OK" in output
```

**Step 2: Run test to verify it fails**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_validate.py -v`
Expected: FAIL with "ModuleNotFoundError: No module named 'sma_merge.validate'"

**Step 3: Write minimal implementation**

```python
# bin/sma_merge/validate.py
"""Validate and group MinKNOW runs for merging."""
from __future__ import annotations

from collections import defaultdict

from sma_merge.models import RunInfo, RunGroup


def validate_runs(runs: list[RunInfo]) -> list[RunGroup]:
    """Group runs by flow_cell_id and validate consistency within each group."""
    by_flowcell: dict[str, list[RunInfo]] = defaultdict(list)
    for run in runs:
        by_flowcell[run.flow_cell_id].append(run)

    groups: list[RunGroup] = []
    for fc_id, fc_runs in sorted(by_flowcell.items()):
        issues: list[str] = []

        # Check basecall model consistency
        models = {r.basecall_model for r in fc_runs}
        if len(models) > 1:
            issues.append(f"Inconsistent basecall models: {models}")

        # Check protocol group consistency
        protocols = {r.protocol_group_id for r in fc_runs}
        if len(protocols) > 1:
            issues.append(f"Multiple protocol groups on same flowcell: {protocols}")

        # Warn if sample_id is empty
        if all(r.sample_id == "" for r in fc_runs):
            issues.append("Warning: sample_id is empty for all runs (common with MinKNOW)")

        groups.append(RunGroup(
            flow_cell_id=fc_id,
            runs=fc_runs,
            basecall_model=fc_runs[0].basecall_model,
            is_consistent=not any(
                issue for issue in issues if not issue.startswith("Warning:")
            ),
            issues=issues,
        ))

    return groups


def format_validation(groups: list[RunGroup]) -> str:
    """Format validation results for display."""
    lines: list[str] = []
    for g in groups:
        status = "OK" if g.is_consistent else "FAIL"
        lines.append(f"[{status}] FlowCell {g.flow_cell_id}: {len(g.runs)} run(s), model={g.basecall_model}")
        for issue in g.issues:
            prefix = "  WARN:" if issue.startswith("Warning:") else "  ERROR:"
            lines.append(f"{prefix} {issue}")
    return "\n".join(lines)
```

**Step 4: Run test to verify it passes**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_validate.py -v`
Expected: 8 PASSED

**Step 5: Commit**

```bash
cd /tmp/ont-sma-seq && git add bin/sma_merge/validate.py tests/test_sma_merge_validate.py && git commit -m "feat(sma-merge): add run validation and grouping"
```

---

### Task 4: Read ID Collection + Subsampling

**Files:**
- Create: `bin/sma_merge/subsample.py`
- Test: `tests/test_sma_merge_subsample.py`

**Context:** Subsampling collects all read IDs from POD5 files, randomly selects N, writes a read-ID file, then calls `pod5 filter` to extract those reads. The `pod5 filter` CLI: `pod5 filter input1.pod5 input2.pod5 --output out.pod5 --ids read_ids.txt`. The POD5 Python API: `p5.Reader(path).reads()` yields reads with `.read_id` (UUID object, use `str()` to convert).

**Step 1: Write the failing test**

```python
# tests/test_sma_merge_subsample.py
"""Tests for POD5 read ID collection and subsampling."""
from __future__ import annotations

from pathlib import Path
from unittest.mock import MagicMock, patch, call
from uuid import UUID

import pytest


def _mock_pod5_reader(read_ids: list[str]):
    """Create a mock pod5 Reader that yields reads with given IDs."""
    reads = []
    for rid in read_ids:
        mock_read = MagicMock()
        mock_read.read_id = UUID(rid) if len(rid) == 36 else rid
        reads.append(mock_read)

    reader = MagicMock()
    reader.__enter__ = MagicMock(return_value=reader)
    reader.__exit__ = MagicMock(return_value=False)
    reader.reads.return_value = iter(reads)
    return reader


# Use deterministic UUIDs for testing
TEST_UUIDS = [f"00000000-0000-0000-0000-{i:012d}" for i in range(20)]


class TestCollectReadIds:

    def test_collects_from_single_file(self, tmp_path):
        pod5_dir = tmp_path / "pod5_pass"
        pod5_dir.mkdir()
        (pod5_dir / "chunk_0.pod5").touch()

        reader = _mock_pod5_reader(TEST_UUIDS[:5])
        with patch("sma_merge.subsample.p5.Reader", return_value=reader):
            from sma_merge.subsample import collect_read_ids
            ids = collect_read_ids(pod5_dir)

        assert len(ids) == 5
        assert ids[0] == TEST_UUIDS[0]

    def test_collects_from_subdirectories(self, tmp_path):
        pod5_dir = tmp_path / "pod5_pass"
        (pod5_dir / "mixed").mkdir(parents=True)
        (pod5_dir / "mixed" / "chunk_0.pod5").touch()
        (pod5_dir / "mixed" / "chunk_1.pod5").touch()

        reader1 = _mock_pod5_reader(TEST_UUIDS[:3])
        reader2 = _mock_pod5_reader(TEST_UUIDS[3:6])
        with patch("sma_merge.subsample.p5.Reader", side_effect=[reader1, reader2]):
            from sma_merge.subsample import collect_read_ids
            ids = collect_read_ids(pod5_dir)

        assert len(ids) == 6


class TestSubsample:

    def test_subsample_selects_n_reads(self, tmp_path):
        pod5_dir = tmp_path / "pod5_pass"
        pod5_dir.mkdir()
        (pod5_dir / "chunk_0.pod5").touch()
        output = tmp_path / "out.pod5"

        reader = _mock_pod5_reader(TEST_UUIDS[:10])
        with patch("sma_merge.subsample.p5.Reader", return_value=reader), \
             patch("sma_merge.subsample.subprocess.run") as mock_run:
            from sma_merge.subsample import subsample_pod5
            selected = subsample_pod5(pod5_dir, output, n_reads=5, seed=42)

        assert len(selected) == 5
        # With seed=42, results are deterministic
        selected2 = None
        reader2 = _mock_pod5_reader(TEST_UUIDS[:10])
        with patch("sma_merge.subsample.p5.Reader", return_value=reader2), \
             patch("sma_merge.subsample.subprocess.run"):
            selected2 = subsample_pod5(pod5_dir, output, n_reads=5, seed=42)
        assert selected == selected2

    def test_subsample_caps_at_total(self, tmp_path):
        pod5_dir = tmp_path / "pod5_pass"
        pod5_dir.mkdir()
        (pod5_dir / "chunk_0.pod5").touch()
        output = tmp_path / "out.pod5"

        reader = _mock_pod5_reader(TEST_UUIDS[:3])
        with patch("sma_merge.subsample.p5.Reader", return_value=reader), \
             patch("sma_merge.subsample.subprocess.run"):
            from sma_merge.subsample import subsample_pod5
            selected = subsample_pod5(pod5_dir, output, n_reads=100, seed=42)

        assert len(selected) == 3  # Only 3 available

    def test_subsample_calls_pod5_filter(self, tmp_path):
        pod5_dir = tmp_path / "pod5_pass"
        pod5_dir.mkdir()
        (pod5_dir / "chunk_0.pod5").touch()
        output = tmp_path / "out.pod5"

        reader = _mock_pod5_reader(TEST_UUIDS[:5])
        with patch("sma_merge.subsample.p5.Reader", return_value=reader), \
             patch("sma_merge.subsample.subprocess.run") as mock_run:
            from sma_merge.subsample import subsample_pod5
            subsample_pod5(pod5_dir, output, n_reads=3, seed=42)

        mock_run.assert_called_once()
        cmd = mock_run.call_args[0][0]
        assert cmd[0] == "pod5"
        assert cmd[1] == "filter"
        assert "--output" in cmd
        assert "--ids" in cmd
```

**Step 2: Run test to verify it fails**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_subsample.py -v`
Expected: FAIL with "ModuleNotFoundError: No module named 'sma_merge.subsample'"

**Step 3: Write minimal implementation**

```python
# bin/sma_merge/subsample.py
"""Subsample reads from POD5 files."""
from __future__ import annotations

import subprocess
import tempfile
from pathlib import Path

import numpy as np
import pod5 as p5


def collect_read_ids(pod5_dir: Path) -> list[str]:
    """Collect all read IDs from POD5 files under a directory."""
    read_ids: list[str] = []
    pod5_files = sorted(pod5_dir.rglob("*.pod5"))
    for pod5_file in pod5_files:
        with p5.Reader(pod5_file) as reader:
            for read in reader.reads():
                read_ids.append(str(read.read_id))
    return read_ids


def subsample_pod5(
    pod5_dir: Path,
    output_pod5: Path,
    n_reads: int,
    seed: int = 42,
) -> list[str]:
    """Subsample N reads from POD5 files and write to a new POD5.

    Returns the list of selected read IDs.
    """
    all_ids = collect_read_ids(pod5_dir)
    rng = np.random.default_rng(seed)
    n = min(n_reads, len(all_ids))
    indices = rng.choice(len(all_ids), size=n, replace=False)
    selected = sorted([all_ids[i] for i in indices])

    # Write read IDs to temp file for pod5 filter
    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".txt", delete=False
    ) as f:
        for rid in selected:
            f.write(f"{rid}\n")
        id_file = Path(f.name)

    try:
        pod5_files = sorted(pod5_dir.rglob("*.pod5"))
        output_pod5.parent.mkdir(parents=True, exist_ok=True)
        subprocess.run(
            [
                "pod5", "filter",
                *[str(f) for f in pod5_files],
                "--output", str(output_pod5),
                "--ids", str(id_file),
            ],
            check=True,
        )
    finally:
        id_file.unlink(missing_ok=True)

    return selected
```

**Step 4: Run test to verify it passes**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_subsample.py -v`
Expected: 5 PASSED

**Step 5: Commit**

```bash
cd /tmp/ont-sma-seq && git add bin/sma_merge/subsample.py tests/test_sma_merge_subsample.py && git commit -m "feat(sma-merge): add read ID collection and subsampling"
```

---

### Task 5: End Reason Tagging

**Files:**
- Create: `bin/sma_merge/tag.py`
- Test: `tests/test_sma_merge_tag.py`

**Context:** Dorado does not include `end_reason` in its BAM output. We extract it from POD5 metadata and add it as a custom `er` tag to each BAM read. POD5 end reason is an enum: `read.end_reason.reason.name` gives strings like `SIGNAL_POSITIVE`, `DATA_SERVICE_UNBLOCK_MUX_CHANGE`, etc. We also add `sl` (signal length = num_samples) as a convenience tag. BAM tagging uses pysam: `read.set_tag("er", value, "Z")` for string, `read.set_tag("sl", value, "i")` for int.

**Step 1: Write the failing test**

```python
# tests/test_sma_merge_tag.py
"""Tests for POD5 end_reason extraction and BAM tagging."""
from __future__ import annotations

from pathlib import Path
from unittest.mock import MagicMock, patch

import pysam
import pytest


def _make_ubam(bam_path: Path, read_ids: list[str], seq_len: int = 100):
    """Create a minimal unaligned BAM for testing."""
    header = pysam.AlignmentHeader.from_dict({"HD": {"VN": "1.6", "SO": "unsorted"}})
    with pysam.AlignmentFile(str(bam_path), "wb", header=header) as af:
        for rid in read_ids:
            seg = pysam.AlignedSegment(header)
            seg.query_name = rid
            seg.query_sequence = "A" * seq_len
            seg.query_qualities = pysam.qualitystring_to_array("I" * seq_len)
            seg.flag = 4  # unmapped
            af.write(seg)


TEST_UUIDS = [f"00000000-0000-0000-0000-{i:012d}" for i in range(5)]


class TestBuildPod5Lookup:

    def test_builds_lookup_from_mock(self, tmp_path):
        pod5_file = tmp_path / "test.pod5"
        pod5_file.touch()

        mock_reads = []
        for i, rid in enumerate(TEST_UUIDS[:3]):
            r = MagicMock()
            r.read_id = rid
            r.end_reason.reason.name = ["SIGNAL_POSITIVE", "MUX_CHANGE", "DATA_SERVICE_UNBLOCK_MUX_CHANGE"][i]
            r.num_samples = [5000, 3000, 8000][i]
            mock_reads.append(r)

        reader = MagicMock()
        reader.__enter__ = MagicMock(return_value=reader)
        reader.__exit__ = MagicMock(return_value=False)
        reader.reads.return_value = iter(mock_reads)

        with patch("sma_merge.tag.p5.Reader", return_value=reader):
            from sma_merge.tag import build_pod5_lookup
            lookup = build_pod5_lookup(pod5_file)

        assert len(lookup) == 3
        assert lookup[TEST_UUIDS[0]] == ("signal_positive", 5000)
        assert lookup[TEST_UUIDS[1]] == ("mux_change", 3000)
        assert lookup[TEST_UUIDS[2]] == ("data_service_unblock_mux_change", 8000)


class TestTagBam:

    def test_adds_er_and_sl_tags(self, tmp_path):
        input_bam = tmp_path / "input.bam"
        output_bam = tmp_path / "output.bam"
        _make_ubam(input_bam, TEST_UUIDS[:3])

        lookup = {
            TEST_UUIDS[0]: ("signal_positive", 5000),
            TEST_UUIDS[1]: ("mux_change", 3000),
            TEST_UUIDS[2]: ("data_service_unblock_mux_change", 8000),
        }

        from sma_merge.tag import tag_bam
        tagged = tag_bam(input_bam, output_bam, lookup)

        assert tagged == 3

        # Verify tags in output BAM
        with pysam.AlignmentFile(str(output_bam), check_sq=False) as af:
            reads = list(af)
        assert len(reads) == 3
        assert reads[0].get_tag("er") == "signal_positive"
        assert reads[0].get_tag("sl") == 5000
        assert reads[2].get_tag("er") == "data_service_unblock_mux_change"

    def test_handles_missing_reads_in_lookup(self, tmp_path):
        input_bam = tmp_path / "input.bam"
        output_bam = tmp_path / "output.bam"
        _make_ubam(input_bam, TEST_UUIDS[:3])

        # Only have lookup for first read
        lookup = {TEST_UUIDS[0]: ("signal_positive", 5000)}

        from sma_merge.tag import tag_bam
        tagged = tag_bam(input_bam, output_bam, lookup)

        assert tagged == 1  # Only 1 of 3 tagged

        with pysam.AlignmentFile(str(output_bam), check_sq=False) as af:
            reads = list(af)
        assert len(reads) == 3  # All reads still in output
        assert reads[0].has_tag("er")
        assert not reads[1].has_tag("er")
```

**Step 2: Run test to verify it fails**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_tag.py -v`
Expected: FAIL with "ModuleNotFoundError: No module named 'sma_merge.tag'"

**Step 3: Write minimal implementation**

```python
# bin/sma_merge/tag.py
"""Extract end_reason from POD5 and tag BAM reads."""
from __future__ import annotations

from pathlib import Path

import pod5 as p5
import pysam


def build_pod5_lookup(pod5_path: Path) -> dict[str, tuple[str, int]]:
    """Build a {read_id: (end_reason, num_samples)} lookup from POD5 file(s).

    Parameters
    ----------
    pod5_path : Path
        A single POD5 file or a directory containing POD5 files.
    """
    lookup: dict[str, tuple[str, int]] = {}
    if pod5_path.is_dir():
        pod5_files = sorted(pod5_path.rglob("*.pod5"))
    else:
        pod5_files = [pod5_path]

    for f in pod5_files:
        with p5.Reader(f) as reader:
            for read in reader.reads():
                er = read.end_reason.reason.name.lower()
                lookup[str(read.read_id)] = (er, read.num_samples)

    return lookup


def tag_bam(
    input_bam: Path,
    output_bam: Path,
    pod5_lookup: dict[str, tuple[str, int]],
) -> int:
    """Add end_reason (er) and signal_length (sl) tags to BAM reads.

    Returns the number of reads successfully tagged.
    """
    in_af = pysam.AlignmentFile(str(input_bam), check_sq=False)
    output_bam.parent.mkdir(parents=True, exist_ok=True)
    out_af = pysam.AlignmentFile(str(output_bam), "wb", header=in_af.header)

    tagged = 0
    for read in in_af:
        rid = read.query_name
        if rid in pod5_lookup:
            er, sl = pod5_lookup[rid]
            read.set_tag("er", er, "Z")
            read.set_tag("sl", sl, "i")
            tagged += 1
        out_af.write(read)

    in_af.close()
    out_af.close()
    return tagged
```

**Step 4: Run test to verify it passes**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_tag.py -v`
Expected: 4 PASSED

**Step 5: Commit**

```bash
cd /tmp/ont-sma-seq && git add bin/sma_merge/tag.py tests/test_sma_merge_tag.py && git commit -m "feat(sma-merge): add end_reason extraction and BAM tagging"
```

---

### Task 6: Basecall + POD5 Merge Wrappers

**Files:**
- Create: `bin/sma_merge/basecall.py`
- Test: `tests/test_sma_merge_basecall.py`

**Context:** The `merge_pod5s` function calls `pod5 merge` to combine POD5 files. The `basecall` function calls `dorado basecaller` with `--no-trim` (no adapter trimming) and no `--kit-name` (no demultiplexing). Dorado outputs unaligned BAM to stdout by default. Dorado binary is at `~/dorado/bin/dorado` or in PATH. The model name comes from POD5 metadata (e.g., `dna_r10.4.1_e8.2_400bps_hac@v5.2.0`).

**Step 1: Write the failing test**

```python
# tests/test_sma_merge_basecall.py
"""Tests for POD5 merge and dorado basecalling wrappers."""
from __future__ import annotations

from pathlib import Path
from unittest.mock import patch, call, MagicMock

import pytest


class TestMergePod5s:

    def test_calls_pod5_merge(self, tmp_path):
        # Create fake pod5 dirs with files
        dir1 = tmp_path / "run1" / "pod5_pass"
        dir1.mkdir(parents=True)
        (dir1 / "a.pod5").touch()
        (dir1 / "b.pod5").touch()

        dir2 = tmp_path / "run2" / "pod5_pass"
        dir2.mkdir(parents=True)
        (dir2 / "c.pod5").touch()

        output = tmp_path / "merged.pod5"

        with patch("sma_merge.basecall.subprocess.run") as mock_run:
            from sma_merge.basecall import merge_pod5s
            merge_pod5s([dir1, dir2], output)

        mock_run.assert_called_once()
        cmd = mock_run.call_args[0][0]
        assert cmd[0] == "pod5"
        assert cmd[1] == "merge"
        assert "--output" in cmd
        assert str(output) in cmd
        # Should include all 3 pod5 files
        pod5_args = [a for a in cmd if a.endswith(".pod5") and a != str(output)]
        assert len(pod5_args) == 3


class TestBasecall:

    def test_calls_dorado_with_correct_flags(self, tmp_path):
        pod5 = tmp_path / "input.pod5"
        pod5.touch()
        output = tmp_path / "output.bam"

        with patch("sma_merge.basecall.subprocess.run") as mock_run, \
             patch("builtins.open", MagicMock()):
            from sma_merge.basecall import basecall
            basecall(
                pod5_path=pod5,
                output_bam=output,
                model="dna_r10.4.1_e8.2_400bps_hac@v5.2.0",
            )

        mock_run.assert_called_once()
        cmd = mock_run.call_args[0][0]
        assert "basecaller" in cmd[0] or "basecaller" in cmd[1]
        assert "--no-trim" in cmd
        assert "--kit-name" not in cmd
        assert "--emit-moves" in cmd
        assert "dna_r10.4.1_e8.2_400bps_hac@v5.2.0" in cmd

    def test_finds_dorado_in_home(self, tmp_path):
        from sma_merge.basecall import find_dorado
        # Should find dorado at ~/dorado/bin/dorado or in PATH
        dorado_path = find_dorado()
        # Just verify it returns a string (path may or may not exist in test env)
        assert isinstance(dorado_path, str)

    def test_custom_dorado_path(self, tmp_path):
        pod5 = tmp_path / "input.pod5"
        pod5.touch()
        output = tmp_path / "output.bam"

        with patch("sma_merge.basecall.subprocess.run") as mock_run, \
             patch("builtins.open", MagicMock()):
            from sma_merge.basecall import basecall
            basecall(
                pod5_path=pod5,
                output_bam=output,
                model="hac@v5.2.0",
                dorado_path="/custom/dorado",
            )

        cmd = mock_run.call_args[0][0]
        assert cmd[0] == "/custom/dorado"
```

**Step 2: Run test to verify it fails**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_basecall.py -v`
Expected: FAIL with "ModuleNotFoundError: No module named 'sma_merge.basecall'"

**Step 3: Write minimal implementation**

```python
# bin/sma_merge/basecall.py
"""POD5 merging and dorado basecalling wrappers."""
from __future__ import annotations

import shutil
import subprocess
from pathlib import Path


def find_dorado() -> str:
    """Find the dorado binary, checking PATH then common locations."""
    # Check PATH first
    dorado_in_path = shutil.which("dorado")
    if dorado_in_path:
        return dorado_in_path

    # Check common locations
    home = Path.home()
    candidates = [
        home / "dorado" / "bin" / "dorado",
        home / ".local" / "bin" / "dorado",
        Path("/usr/local/bin/dorado"),
    ]
    for candidate in candidates:
        if candidate.exists():
            return str(candidate)

    return "dorado"  # Fall back, will fail at runtime if not found


def merge_pod5s(pod5_dirs: list[Path], output_pod5: Path) -> None:
    """Merge all POD5 files from multiple directories into one file."""
    all_files: list[Path] = []
    for d in pod5_dirs:
        all_files.extend(sorted(d.rglob("*.pod5")))

    if not all_files:
        raise ValueError("No POD5 files found in provided directories")

    output_pod5.parent.mkdir(parents=True, exist_ok=True)
    subprocess.run(
        [
            "pod5", "merge",
            *[str(f) for f in all_files],
            "--output", str(output_pod5),
        ],
        check=True,
    )


def basecall(
    pod5_path: Path,
    output_bam: Path,
    model: str,
    device: str = "auto",
    emit_moves: bool = True,
    dorado_path: str | None = None,
) -> None:
    """Run dorado basecaller on a POD5 file.

    Produces an unaligned BAM (no trimming, no demultiplexing).
    """
    dorado = dorado_path or find_dorado()
    output_bam.parent.mkdir(parents=True, exist_ok=True)

    cmd = [
        dorado, "basecaller",
        model,
        str(pod5_path),
        "--no-trim",
        "--device", device,
    ]
    if emit_moves:
        cmd.append("--emit-moves")

    # Dorado outputs unaligned BAM to stdout by default
    with open(output_bam, "wb") as f:
        subprocess.run(cmd, stdout=f, check=True)
```

**Step 4: Run test to verify it passes**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_basecall.py -v`
Expected: 4 PASSED

**Step 5: Commit**

```bash
cd /tmp/ont-sma-seq && git add bin/sma_merge/basecall.py tests/test_sma_merge_basecall.py && git commit -m "feat(sma-merge): add POD5 merge and dorado basecalling wrappers"
```

---

### Task 7: CLI Entry Point

**Files:**
- Create: `bin/sma_merge/cli.py`
- Test: `tests/test_sma_merge_cli.py`

**Context:** The CLI uses argparse with three subcommands: `discover`, `merge`, `subsample`. Each prints progress to stdout. The `discover` subcommand just scans and prints what it found. The `merge` and `subsample` subcommands run the full pipeline. All subcommands accept an experiment path. The CLI entry point is `python -m sma_merge`.

**Step 1: Write the failing test**

```python
# tests/test_sma_merge_cli.py
"""Tests for sma-merge CLI."""
from __future__ import annotations

from pathlib import Path
from unittest.mock import patch, MagicMock

import pytest


class TestCliParsing:

    def test_discover_subcommand(self):
        from sma_merge.cli import build_parser
        parser = build_parser()
        args = parser.parse_args(["discover", "/tmp/experiment"])
        assert args.command == "discover"
        assert args.path == Path("/tmp/experiment")

    def test_merge_subcommand(self):
        from sma_merge.cli import build_parser
        parser = build_parser()
        args = parser.parse_args(["merge", "/tmp/experiment", "-o", "/tmp/out"])
        assert args.command == "merge"
        assert args.path == Path("/tmp/experiment")
        assert args.output == Path("/tmp/out")

    def test_subsample_subcommand(self):
        from sma_merge.cli import build_parser
        parser = build_parser()
        args = parser.parse_args(["subsample", "/tmp/exp", "-n", "5000", "-o", "/tmp/out"])
        assert args.command == "subsample"
        assert args.num_reads == 5000
        assert args.seed == 42  # default

    def test_subsample_custom_seed(self):
        from sma_merge.cli import build_parser
        parser = build_parser()
        args = parser.parse_args(["subsample", "/tmp/exp", "-n", "100", "-o", "/tmp/out", "--seed", "99"])
        assert args.seed == 99

    def test_merge_custom_device(self):
        from sma_merge.cli import build_parser
        parser = build_parser()
        args = parser.parse_args(["merge", "/tmp/exp", "-o", "/tmp/out", "--device", "cuda:0"])
        assert args.device == "cuda:0"

    def test_dorado_path_flag(self):
        from sma_merge.cli import build_parser
        parser = build_parser()
        args = parser.parse_args(["merge", "/tmp/exp", "-o", "/tmp/out", "--dorado", "/opt/dorado"])
        assert args.dorado == Path("/opt/dorado")


class TestDiscoverCommand:

    def test_discover_prints_table(self, tmp_path, capsys):
        from sma_merge.models import RunInfo

        mock_runs = [
            RunInfo(
                run_dir=tmp_path,
                flow_cell_id="FBD66244",
                device_id="MD-101527",
                protocol_group_id="test",
                basecall_model="hac@v5.2.0",
                sample_id="",
                run_id="abc",
                sample_rate=5000,
                pod5_dir=tmp_path / "pod5_pass",
                pod5_count=10,
                mod_base_models="",
            ),
        ]

        with patch("sma_merge.cli.discover_runs", return_value=mock_runs), \
             patch("sma_merge.cli.validate_runs") as mock_val:
            mock_val.return_value = []
            from sma_merge.cli import cmd_discover
            cmd_discover(tmp_path)

        captured = capsys.readouterr()
        assert "FBD66244" in captured.out
```

**Step 2: Run test to verify it fails**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_cli.py -v`
Expected: FAIL with "ModuleNotFoundError: No module named 'sma_merge.cli'"

**Step 3: Write minimal implementation**

```python
# bin/sma_merge/cli.py
"""CLI entry point for sma-merge."""
from __future__ import annotations

import argparse
import sys
from pathlib import Path

from sma_merge.discover import discover_runs, format_discovery_table
from sma_merge.validate import validate_runs, format_validation


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        prog="sma-merge",
        description="SMA-seq experiment merge tool: discover, validate, merge, or subsample MinKNOW runs.",
    )
    sub = parser.add_subparsers(dest="command", required=True)

    # discover
    disc = sub.add_parser("discover", help="Discover MinKNOW runs and show metadata")
    disc.add_argument("path", type=Path, help="Path to experiment directory")

    # merge
    merge = sub.add_parser("merge", help="Full merge: combine POD5s + re-basecall")
    merge.add_argument("path", type=Path, help="Path to experiment directory")
    merge.add_argument("-o", "--output", type=Path, required=True, help="Output directory")
    merge.add_argument("--device", default="auto", help="Dorado device (default: auto)")
    merge.add_argument("--dorado", type=Path, default=None, help="Path to dorado binary")

    # subsample
    sample = sub.add_parser("subsample", help="Subsample N reads + basecall")
    sample.add_argument("path", type=Path, help="Path to experiment directory")
    sample.add_argument("-n", "--num-reads", type=int, required=True, help="Number of reads to subsample")
    sample.add_argument("-o", "--output", type=Path, required=True, help="Output directory")
    sample.add_argument("--seed", type=int, default=42, help="Random seed (default: 42)")
    sample.add_argument("--device", default="auto", help="Dorado device (default: auto)")
    sample.add_argument("--dorado", type=Path, default=None, help="Path to dorado binary")

    return parser


def cmd_discover(experiment_path: Path) -> None:
    """Run the discover subcommand."""
    print(f"Scanning {experiment_path} for MinKNOW runs...\n")
    runs = discover_runs(experiment_path)

    if not runs:
        print("No runs found.")
        return

    print(format_discovery_table(runs))
    print()

    groups = validate_runs(runs)
    print(format_validation(groups))


def cmd_merge(experiment_path: Path, output_dir: Path, device: str, dorado_path: Path | None) -> None:
    """Run the full merge pipeline."""
    from sma_merge.basecall import merge_pod5s, basecall
    from sma_merge.tag import build_pod5_lookup, tag_bam

    print(f"Scanning {experiment_path}...")
    runs = discover_runs(experiment_path)
    if not runs:
        print("No runs found.")
        sys.exit(1)

    groups = validate_runs(runs)
    print(format_validation(groups))

    # Check for issues
    for g in groups:
        if not g.is_consistent:
            print(f"\nERROR: Inconsistent runs in flowcell {g.flow_cell_id}. Aborting.")
            sys.exit(1)

    output_dir.mkdir(parents=True, exist_ok=True)

    for g in groups:
        name = g.flow_cell_id
        pod5_dirs = [r.pod5_dir for r in g.runs]
        model = g.basecall_model

        # Step 1: Merge POD5s
        merged_pod5 = output_dir / f"{name}_merged.pod5"
        print(f"\nMerging POD5 files -> {merged_pod5}")
        merge_pod5s(pod5_dirs, merged_pod5)

        # Step 2: Basecall
        raw_bam = output_dir / f"{name}_raw.bam"
        print(f"Basecalling with {model} -> {raw_bam}")
        basecall(
            pod5_path=merged_pod5,
            output_bam=raw_bam,
            model=model,
            device=device,
            dorado_path=str(dorado_path) if dorado_path else None,
        )

        # Step 3: Tag with end_reason
        print("Building end_reason lookup from POD5...")
        lookup = build_pod5_lookup(merged_pod5)
        output_bam = output_dir / f"{name}_merged.bam"
        print(f"Tagging BAM -> {output_bam}")
        tagged = tag_bam(raw_bam, output_bam, lookup)
        print(f"Tagged {tagged}/{len(lookup)} reads with end_reason")

        # Clean up raw BAM
        raw_bam.unlink()

    print("\nDone!")


def cmd_subsample(
    experiment_path: Path, output_dir: Path, n_reads: int,
    seed: int, device: str, dorado_path: Path | None,
) -> None:
    """Run the subsample pipeline."""
    from sma_merge.basecall import basecall
    from sma_merge.subsample import subsample_pod5
    from sma_merge.tag import build_pod5_lookup, tag_bam

    print(f"Scanning {experiment_path}...")
    runs = discover_runs(experiment_path)
    if not runs:
        print("No runs found.")
        sys.exit(1)

    groups = validate_runs(runs)
    print(format_validation(groups))

    output_dir.mkdir(parents=True, exist_ok=True)

    for g in groups:
        name = g.flow_cell_id
        model = g.basecall_model

        # Collect all pod5 dirs for this group
        pod5_dirs = [r.pod5_dir for r in g.runs]

        # For subsampling, we need a single source. If multiple dirs, merge first.
        if len(pod5_dirs) == 1:
            source_dir = pod5_dirs[0]
        else:
            from sma_merge.basecall import merge_pod5s
            merged = output_dir / f"{name}_temp_merged.pod5"
            print(f"Merging POD5 files from {len(pod5_dirs)} runs...")
            merge_pod5s(pod5_dirs, merged)
            # Use merged file's parent as source
            source_dir = merged.parent

        # Step 1: Subsample
        sub_pod5 = output_dir / f"{name}_sub{n_reads}.pod5"
        print(f"\nSubsampling {n_reads} reads -> {sub_pod5}")
        selected = subsample_pod5(source_dir, sub_pod5, n_reads=n_reads, seed=seed)
        print(f"Selected {len(selected)} reads")

        # Step 2: Basecall
        raw_bam = output_dir / f"{name}_sub{n_reads}_raw.bam"
        print(f"Basecalling with {model} -> {raw_bam}")
        basecall(
            pod5_path=sub_pod5,
            output_bam=raw_bam,
            model=model,
            device=device,
            dorado_path=str(dorado_path) if dorado_path else None,
        )

        # Step 3: Tag with end_reason
        print("Building end_reason lookup from POD5...")
        lookup = build_pod5_lookup(sub_pod5)
        output_bam = output_dir / f"{name}_sub{n_reads}.bam"
        print(f"Tagging BAM -> {output_bam}")
        tagged = tag_bam(raw_bam, output_bam, lookup)
        print(f"Tagged {tagged}/{len(selected)} reads with end_reason")

        # Clean up
        raw_bam.unlink()

    print("\nDone!")


def main() -> None:
    parser = build_parser()
    args = parser.parse_args()

    if args.command == "discover":
        cmd_discover(args.path)
    elif args.command == "merge":
        cmd_merge(args.path, args.output, args.device, args.dorado)
    elif args.command == "subsample":
        cmd_subsample(
            args.path, args.output, args.num_reads,
            args.seed, args.device, args.dorado,
        )


if __name__ == "__main__":
    main()
```

Also create `__main__.py` so `python -m sma_merge` works:

```python
# bin/sma_merge/__main__.py
"""Allow running as python -m sma_merge."""
from sma_merge.cli import main

main()
```

**Step 4: Run test to verify it passes**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_cli.py -v`
Expected: 7 PASSED

**Step 5: Commit**

```bash
cd /tmp/ont-sma-seq && git add bin/sma_merge/cli.py bin/sma_merge/__main__.py tests/test_sma_merge_cli.py && git commit -m "feat(sma-merge): add CLI entry point with discover/merge/subsample subcommands"
```

---

### Task 8: Integration Test with Real Data

**Files:**
- Create: `tests/test_sma_merge_integration.py`

**Context:** Real experiment data is at `/tmp/one_nick_data/` (symlink to Dropbox). The MinKNOW run is at `/tmp/one_nick_data/no_sample_id/20251230_1709_MD-101527_FBD66244_f28bd4df/`. This test verifies the full discover -> validate -> subsample pipeline works end-to-end. It uses the real POD5 files but a small subsample (50 reads) to keep it fast. Dorado basecalling is skipped (mocked) since it requires GPU. The end_reason tagging is tested against real POD5 data.

**Step 1: Write the failing test**

```python
# tests/test_sma_merge_integration.py
"""Integration tests for sma-merge with real experiment data.

These tests require real data at /tmp/one_nick_data/.
Skip if data is not available.
"""
from __future__ import annotations

from pathlib import Path
from unittest.mock import patch

import pytest

ONE_NICK_DATA = Path("/tmp/one_nick_data")
HAS_REAL_DATA = ONE_NICK_DATA.exists() and any(ONE_NICK_DATA.rglob("pod5_pass"))

skip_no_data = pytest.mark.skipif(
    not HAS_REAL_DATA,
    reason="Real experiment data not available at /tmp/one_nick_data/",
)


@skip_no_data
class TestDiscoverRealData:

    def test_discovers_one_nick_run(self):
        from sma_merge.discover import discover_runs
        runs = discover_runs(ONE_NICK_DATA)
        assert len(runs) >= 1
        run = runs[0]
        assert run.flow_cell_id == "FBD66244"
        assert run.device_id == "MD-101527"
        assert "hac" in run.basecall_model
        assert run.pod5_count > 0
        assert run.sample_rate == 5000

    def test_validates_one_nick(self):
        from sma_merge.discover import discover_runs
        from sma_merge.validate import validate_runs
        runs = discover_runs(ONE_NICK_DATA)
        groups = validate_runs(runs)
        assert len(groups) == 1
        assert groups[0].is_consistent


@skip_no_data
class TestSubsampleRealData:

    def test_subsample_50_reads(self, tmp_path):
        from sma_merge.discover import discover_runs
        from sma_merge.subsample import subsample_pod5

        runs = discover_runs(ONE_NICK_DATA)
        pod5_dir = runs[0].pod5_dir

        output = tmp_path / "sub50.pod5"
        selected = subsample_pod5(pod5_dir, output, n_reads=50, seed=42)

        assert len(selected) == 50
        assert output.exists()
        assert output.stat().st_size > 0

    def test_end_reason_lookup_from_subsampled(self, tmp_path):
        from sma_merge.discover import discover_runs
        from sma_merge.subsample import subsample_pod5
        from sma_merge.tag import build_pod5_lookup

        runs = discover_runs(ONE_NICK_DATA)
        pod5_dir = runs[0].pod5_dir

        output = tmp_path / "sub50.pod5"
        selected = subsample_pod5(pod5_dir, output, n_reads=50, seed=42)

        lookup = build_pod5_lookup(output)
        assert len(lookup) == 50

        # Check that end reasons are valid strings
        valid_reasons = {
            "unknown", "mux_change", "unblock_mux_change",
            "data_service_unblock_mux_change", "signal_positive",
            "signal_negative", "api_request", "device_data_error",
            "analysis_config_change", "paused",
        }
        for rid, (er, ns) in lookup.items():
            assert er in valid_reasons, f"Unexpected end_reason: {er}"
            assert ns > 0, f"Signal length should be > 0, got {ns}"
```

**Step 2: Run test to verify it fails**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_integration.py -v`
Expected: FAIL (import errors from missing modules) or SKIP (if data not available)

**Step 3: All implementation is already done in previous tasks.** If the tests fail due to bugs, fix them.

**Step 4: Run test to verify it passes**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_integration.py -v`
Expected: 4 PASSED (or SKIPPED if no real data)

Run all tests to make sure nothing is broken:

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_*.py -v`
Expected: All PASSED

**Step 5: Commit**

```bash
cd /tmp/ont-sma-seq && git add tests/test_sma_merge_integration.py && git commit -m "test(sma-merge): add integration tests with real experiment data"
```

---

### Task 9: End-to-End Smoke Test

**Files:**
- Modify: `tests/test_sma_merge_integration.py` (add test)

**Context:** This test runs the full CLI subsample pipeline end-to-end with real data but mocked dorado (since GPU may not be available). It verifies: discovery, validation, subsampling, POD5 output, and end_reason lookup all work together through the CLI interface. This is the final validation that everything is wired correctly.

**Step 1: Write the test**

Add to `tests/test_sma_merge_integration.py`:

```python
@skip_no_data
class TestEndToEndSubsample:

    def test_cli_subsample_pipeline(self, tmp_path, capsys):
        """Full pipeline: discover -> validate -> subsample -> build lookup."""
        from sma_merge.cli import cmd_discover

        # Verify discover works through CLI
        cmd_discover(ONE_NICK_DATA)
        captured = capsys.readouterr()
        assert "FBD66244" in captured.out
        assert "OK" in captured.out

        # Run subsample (mock basecalling since no GPU in test)
        from sma_merge.discover import discover_runs
        from sma_merge.subsample import subsample_pod5
        from sma_merge.tag import build_pod5_lookup

        runs = discover_runs(ONE_NICK_DATA)
        pod5_dir = runs[0].pod5_dir

        sub_pod5 = tmp_path / "sub20.pod5"
        selected = subsample_pod5(pod5_dir, sub_pod5, n_reads=20, seed=123)
        assert len(selected) == 20

        # Verify POD5 lookup
        lookup = build_pod5_lookup(sub_pod5)
        assert len(lookup) == 20
        # All selected IDs should be in lookup
        for rid in selected:
            assert rid in lookup

        # Verify end_reason distribution makes sense
        reasons = [er for er, ns in lookup.values()]
        assert len(set(reasons)) >= 1  # At least 1 unique end reason
        print(f"\nEnd reason distribution: {dict((r, reasons.count(r)) for r in set(reasons))}")
```

**Step 2: Run test**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_integration.py::TestEndToEndSubsample -v -s`
Expected: PASSED with end_reason distribution printed

**Step 3: Run full test suite**

Run: `cd /tmp/ont-sma-seq && python -m pytest tests/test_sma_merge_*.py -v`
Expected: All PASSED

**Step 4: Commit**

```bash
cd /tmp/ont-sma-seq && git add tests/test_sma_merge_integration.py && git commit -m "test(sma-merge): add end-to-end smoke test"
```
